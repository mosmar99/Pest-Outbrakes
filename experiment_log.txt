Experiment Settings:
Batch Size: 32
Epochs: 3
Learning Rate: 0.0008
Patience: 3
Quantile: 0.55
Dropout Rate: 0.4
Activation: Swish
Optimizer: Adam
Batch Normalization: Yes
Network Architecture: [52, 52, 52] -> 1

---

### Experiment 1 ###
Epoch 1/3 - loss: 0.3399 - val_loss: 0.0493
Epoch 2/3 - loss: 0.1081 - val_loss: 0.0342
Epoch 3/3 - loss: 0.0476 - val_loss: 0.0302

Mean Absolute Error: 0.078241
R^2: 0.763796

---

### Experiment 2 ###
Epoch 1/3 - loss: 0.4140 - val_loss: 0.0646
Epoch 2/3 - loss: 0.1644 - val_loss: 0.0373
Epoch 3/3 - loss: 0.0538 - val_loss: 0.0345

Mean Absolute Error: 0.081033
R^2: 0.656925

---

### Experiment 3 ###
Epoch 1/3 - loss: 0.3736 - val_loss: 0.0504
Epoch 2/3 - loss: 0.1279 - val_loss: 0.0355
Epoch 3/3 - loss: 0.0481 - val_loss: 0.0293

Mean Absolute Error: 0.060540
R^2: 0.766909

---

### Final Results ###
Average R^2 over 3 experiments: 0.729210
